{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automated Description Generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuPeoSqUbbIQ",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM0szNibalIm",
        "colab_type": "text"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOpdu424SBXH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "8a74026a-a3b3-4f24-fb54-5ce527abc5b4"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "#Diff and Message for Training\n",
        "id = '1gaDee3qP_OUhpFsFrAXR1QtoLdAqbteS'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train_diff_26208.csv')\n",
        "\n",
        "id = '1GhbL0M2kIzSMuSKRgloH8-NtCjXViq2O'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train_msg_26208.csv')\n",
        "\n",
        "#Diff and Message for Testing\n",
        "id = '1BZf1hw9ugqXI3VWVZDbmRr0P4qn8qh6D'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test_diff_3000.csv')\n",
        "\n",
        "id = '181xwJV5nVLrMEzRr9hqPQBFJmkbpAzBG'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test_msg_3000.csv')\n",
        "print(\"success\")\n",
        "import pandas as pd\n",
        "\n",
        "df_diff_train = pd.read_csv('train_diff_26208.csv', sep=\"\\r\\t\", header=None)\n",
        "df_msg_train = pd.read_csv('train_msg_26208.csv', sep=\"\\r\\t\", header=None)\n",
        "df_diff_test = pd.read_csv('test_diff_3000.csv', sep=\"\\r\\t\", header=None)\n",
        "df_msg_test = pd.read_csv('test_msg_3000.csv', sep=\"\\r\\t\", header=None)\n",
        "\n",
        "\n",
        "diff_train = df_diff_train[0].tolist()\n",
        "msg_train = df_msg_train[0].tolist()\n",
        "diff_test = df_diff_test[0].tolist()\n",
        "msg_test = df_msg_test[0].tolist()\n",
        " \n",
        "\n",
        "print(\"Training:\", len(diff_train), len(msg_train))\n",
        "print(\"Testing:\", len(diff_test), len(msg_test))\n",
        "print(\"diff\")\n",
        "for i in range(0,10):\n",
        "  print(diff_train[i])\n",
        "print(\"message\")\n",
        "for i in range(0,10):\n",
        "  print(msg_train[i])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "success\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 26208 26208\n",
            "Testing: 3000 3000\n",
            "diff\n",
            "new file mode 100755 <nl> index 0000000 . . d125c52 <nl> Binary files / dev / null and b / art / intro . png differ <nl>\n",
            "mmm a / telecomm / java / android / telecomm / Connection . java <nl> ppp b / telecomm / java / android / telecomm / Connection . java <nl> public abstract class Connection { <nl> * / <nl> public static String stateToString ( int state ) { <nl> switch ( state ) { <nl> + case State . INITIALIZING : <nl> + return \" INITIALIZING \" ; <nl> case State . NEW : <nl> return \" NEW \" ; <nl> case State . RINGING : <nl>\n",
            "similarity index 100 % <nl> rename from examples / seneca / bug662 / binary . html <nl> rename to examples / seneca / bug662 / test1 . html <nl>\n",
            "mmm a / modules / apps / collaboration / wiki / . gitrepo <nl> ppp b / modules / apps / collaboration / wiki / . gitrepo <nl> ; <nl> [ subrepo ] <nl> cmdver = liferay <nl> - commit = e17a5e5da4d8f1594040175129627f3e998a76cc <nl> + commit = ec7c0219d8d764010ba9493accae8be3c94785d7 <nl> mode = push <nl> - parent = f49454bc940a22bff107906ad639d2d6c5fff71e <nl> + parent = 3f2abcac9420152ba00be869ca3aa6cb47c07a24 <nl> remote = git @ github . com : liferay / com - liferay - wiki . git <nl> \\ No newline at end of file <nl>\n",
            "mmm a / modules / apps / foundation / microsoft - translator / microsoft - translator / bnd . bnd <nl> ppp b / modules / apps / foundation / microsoft - translator / microsoft - translator / bnd . bnd <nl> Bundle - Name : Liferay Microsoft Translator <nl> Bundle - SymbolicName : com . liferay . microsoft . translator <nl> - Bundle - Version : 1 . 0 . 0 <nl> \\ No newline at end of file <nl> + Bundle - Version : 1 . 0 . 1 <nl> \\ No newline at end of file <nl>\n",
            "mmm a / modules / apps / foundation / portal - cache / . gitrepo <nl> ppp b / modules / apps / foundation / portal - cache / . gitrepo <nl> ; <nl> [ subrepo ] <nl> cmdver = liferay <nl> - commit = 3af56ee36710a7741c38e736433842ce6e466d31 <nl> + commit = 05b9ea8ec936fcac0523f9362dccce6018a1c51f <nl> mode = push <nl> - parent = ddbc36b611af67d5f74bc48295c076a90cb3a152 <nl> + parent = 762b9438f16485938f52ae3fdedf7cfbd8972b74 <nl> remote = git @ github . com : liferay / com - liferay - portal - cache . git <nl> \\ No newline at end of file <nl>\n",
            "mmm a / lib / nokogiri / version . rb <nl> ppp b / lib / nokogiri / version . rb <nl> module Nokogiri <nl> - VERSION = ' 1 . 0 . 5 ' <nl> + VERSION = ' 1 . 0 . 6 ' <nl> end <nl>\n",
            "mmm a / twidere / build . gradle <nl> ppp b / twidere / build . gradle <nl> android { <nl> applicationId \" org . mariotaku . twidere \" <nl> minSdkVersion 14 <nl> targetSdkVersion 25 <nl> - versionCode 233 <nl> - versionName ' 3 . 3 . 15 ' <nl> + versionCode 234 <nl> + versionName ' 3 . 3 . 16 ' <nl> multiDexEnabled true <nl> buildConfigField ' boolean ' , ' LEAK_CANARY_ENABLED ' , ' Boolean . parseBoolean ( \" true \" ) ' <nl>\n",
            "mmm a / CHANGELOG . md <nl> ppp b / CHANGELOG . md <nl> * STORM - 1478 : make bolts getComponentConfiguration method cleaner / simpler <nl> # # 1 . 0 . 0 <nl> + * STORM - 1499 : fix wrong package name for storm trident <nl> * STORM - 1463 : added file scehma to log4j config files for windows env <nl> * STORM - 1485 : DRPC Connectivity Issues <nl> * STORM - 1486 : Fix storm - kafa documentation <nl>\n",
            "Binary files a / webcollector_design . png and b / webcollector_design . png differ <nl>\n",
            "message\n",
            "Added intro image .\n",
            "Fix WTF when creating a lazily initialized connection\n",
            "renamed test .\n",
            "ignore Update ' modules / apps / collaboration / wiki / .\n",
            "ignore microsoft - translator 1 . 0 . 0 prep next\n",
            "ignore Update ' modules / apps / foundation / portal - cache / .\n",
            "bumping up version\n",
            "updated version\n",
            "add STORM - 1499 to CHANGELOG . md\n",
            "add design\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_I823I_ryRx",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-NKd71QSBk9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "a637ba81-9423-462e-a832-1016528f6079"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "#For diff, we only want to keep the text; For Commit Message, we keep the whole sentences.\n",
        "\n",
        "# diff & msg: Case Folding\n",
        "diff_train = [i.lower() for i in diff_train]\n",
        "msg_train = [i.lower() for i in msg_train]\n",
        "diff_test = [i.lower() for i in diff_test]\n",
        "msg_test = [i.lower() for i in msg_test]\n",
        "\n",
        "# diff & msg: Punctuation Removal\n",
        "def remove_punctuation(x):\n",
        "  #remove '<nl>' label \n",
        "  cleaner = re.compile('<.*?>')\n",
        "  x = re.sub(cleaner,'', x) \n",
        "  x = re.sub(r'[^\\w\\s]','', x)\n",
        "  return x\n",
        "\n",
        "diff_train = [remove_punctuation(i) for i in diff_train]\n",
        "msg_train = [remove_punctuation(i) for i in msg_train]\n",
        "diff_test = [remove_punctuation(i) for i in diff_test]\n",
        "msg_test = [remove_punctuation(i) for i in msg_test]\n",
        "for s in range(0,5):\n",
        "  print(diff_train[s]) \n",
        "  \n",
        "# diff: Remove the \"mmm a\"\n",
        "for i in range(0,len(diff_train)):\n",
        "  if \"mmm a\" in diff_train[i]:\n",
        "    diff_train[i]=diff_train[i].replace(\"mmm a  \",\"\")\n",
        "\n",
        "for s in range(0,10):\n",
        "  print(diff_train[s]) \n",
        "\n",
        "# diff & msg: Tokenization\n",
        "diff_train = [word_tokenize(i) for i in diff_train]\n",
        "msg_train = [word_tokenize(i) for i in msg_train]\n",
        "diff_test = [word_tokenize(i) for i in diff_test]\n",
        "msg_test = [word_tokenize(i) for i in msg_test]\n",
        "\n",
        "for s in range(0,5):\n",
        "  print(diff_train[s]) \n",
        "\n",
        "# diff & msg: Stopwords Removal\n",
        "stop_words = sw.words()\n",
        "diff_train_remove_stopwords=[]\n",
        "for diffs in diff_train:\n",
        "    filtered_diffs = [i for i in diffs if not i in stop_words]\n",
        "    diff_train_remove_stopwords.append(filtered_diffs)\n",
        "\n",
        "msg_train_remove_stopwords=[]\n",
        "for msgs in msg_train:\n",
        "    filtered_msgs = [i for i in msgs if not i in stop_words]\n",
        "    msg_train_remove_stopwords.append(filtered_msgs)\n",
        "\n",
        "diff_test_remove_stopwords=[]\n",
        "for diffs in diff_test:\n",
        "    filtered_diffs = [i for i in diffs if not i in stop_words]\n",
        "    diff_test_remove_stopwords.append(filtered_diffs)\n",
        "\n",
        "msg_test_remove_stopwords=[]\n",
        "for msgs in msg_test:\n",
        "    filtered_msgs = [i for i in msgs if not i in stop_words]\n",
        "    msg_test_remove_stopwords.append(filtered_msgs)\n",
        "\n",
        "for s in range(0,5):\n",
        "  print(diff_train_remove_stopwords[s]) \n",
        "\n",
        "#Lemmatisation\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "diff_train_lemmatisation = []\n",
        "for tokens in diff_train_remove_stopwords:\n",
        "    lemma_sentence = [lemmatizer.lemmatize(w) for w in tokens ]\n",
        "    diff_train_lemmatisation.append(lemma_sentence)\n",
        "\n",
        "msg_train_lemmatisation = []\n",
        "for tokens in msg_train_remove_stopwords:\n",
        "    lemma_sentences = [lemmatizer.lemmatize(w) for w in tokens ]\n",
        "    msg_train_lemmatisation.append(lemma_sentences)\n",
        "\n",
        "diff_test_lemmatisation = []\n",
        "for tokens in diff_test_remove_stopwords:\n",
        "    lemma_sentence = [lemmatizer.lemmatize(w) for w in tokens ]\n",
        "    diff_test_lemmatisation.append(lemma_sentence)\n",
        "\n",
        "msg_test_lemmatisation = []\n",
        "for tokens in msg_test_remove_stopwords:\n",
        "    lemma_sentences = [lemmatizer.lemmatize(w) for w in tokens ]\n",
        "    msg_test_lemmatisation.append(lemma_sentences)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "new file mode 100755  index 0000000   d125c52  binary files  dev  null and b  art  intro  png differ \n",
            "mmm a  telecomm  java  android  telecomm  connection  java  ppp b  telecomm  java  android  telecomm  connection  java  public abstract class connection      public static string statetostring  int state    switch  state     case state  initializing    return  initializing    case state  new   return  new    case state  ringing  \n",
            "similarity index 100   rename from examples  seneca  bug662  binary  html  rename to examples  seneca  bug662  test1  html \n",
            "mmm a  modules  apps  collaboration  wiki   gitrepo  ppp b  modules  apps  collaboration  wiki   gitrepo     subrepo   cmdver  liferay   commit  e17a5e5da4d8f1594040175129627f3e998a76cc   commit  ec7c0219d8d764010ba9493accae8be3c94785d7  mode  push   parent  f49454bc940a22bff107906ad639d2d6c5fff71e   parent  3f2abcac9420152ba00be869ca3aa6cb47c07a24  remote  git  github  com  liferay  com  liferay  wiki  git   no newline at end of file \n",
            "mmm a  modules  apps  foundation  microsoft  translator  microsoft  translator  bnd  bnd  ppp b  modules  apps  foundation  microsoft  translator  microsoft  translator  bnd  bnd  bundle  name  liferay microsoft translator  bundle  symbolicname  com  liferay  microsoft  translator   bundle  version  1  0  0   no newline at end of file   bundle  version  1  0  1   no newline at end of file \n",
            "new file mode 100755  index 0000000   d125c52  binary files  dev  null and b  art  intro  png differ \n",
            "telecomm  java  android  telecomm  connection  java  ppp b  telecomm  java  android  telecomm  connection  java  public abstract class connection      public static string statetostring  int state    switch  state     case state  initializing    return  initializing    case state  new   return  new    case state  ringing  \n",
            "similarity index 100   rename from examples  seneca  bug662  binary  html  rename to examples  seneca  bug662  test1  html \n",
            "modules  apps  collaboration  wiki   gitrepo  ppp b  modules  apps  collaboration  wiki   gitrepo     subrepo   cmdver  liferay   commit  e17a5e5da4d8f1594040175129627f3e998a76cc   commit  ec7c0219d8d764010ba9493accae8be3c94785d7  mode  push   parent  f49454bc940a22bff107906ad639d2d6c5fff71e   parent  3f2abcac9420152ba00be869ca3aa6cb47c07a24  remote  git  github  com  liferay  com  liferay  wiki  git   no newline at end of file \n",
            "modules  apps  foundation  microsoft  translator  microsoft  translator  bnd  bnd  ppp b  modules  apps  foundation  microsoft  translator  microsoft  translator  bnd  bnd  bundle  name  liferay microsoft translator  bundle  symbolicname  com  liferay  microsoft  translator   bundle  version  1  0  0   no newline at end of file   bundle  version  1  0  1   no newline at end of file \n",
            "modules  apps  foundation  portal  cache   gitrepo  ppp b  modules  apps  foundation  portal  cache   gitrepo     subrepo   cmdver  liferay   commit  3af56ee36710a7741c38e736433842ce6e466d31   commit  05b9ea8ec936fcac0523f9362dccce6018a1c51f  mode  push   parent  ddbc36b611af67d5f74bc48295c076a90cb3a152   parent  762b9438f16485938f52ae3fdedf7cfbd8972b74  remote  git  github  com  liferay  com  liferay  portal  cache  git   no newline at end of file \n",
            "lib  nokogiri  version  rb  ppp b  lib  nokogiri  version  rb  module nokogiri   version   1  0  5    version   1  0  6   end \n",
            "twidere  build  gradle  ppp b  twidere  build  gradle  android   applicationid  org  mariotaku  twidere   minsdkversion 14  targetsdkversion 25   versioncode 233   versionname  3  3  15    versioncode 234   versionname  3  3  16   multidexenabled true  buildconfigfield  boolean    leak_canary_enabled    boolean  parseboolean   true    \n",
            "changelog  md  ppp b  changelog  md   storm  1478  make bolts getcomponentconfiguration method cleaner  simpler    1  0  0    storm  1499  fix wrong package name for storm trident   storm  1463  added file scehma to log4j config files for windows env   storm  1485  drpc connectivity issues   storm  1486  fix storm  kafa documentation \n",
            "binary files a  webcollector_design  png and b  webcollector_design  png differ \n",
            "['new', 'file', 'mode', '100755', 'index', '0000000', 'd125c52', 'binary', 'files', 'dev', 'null', 'and', 'b', 'art', 'intro', 'png', 'differ']\n",
            "['telecomm', 'java', 'android', 'telecomm', 'connection', 'java', 'ppp', 'b', 'telecomm', 'java', 'android', 'telecomm', 'connection', 'java', 'public', 'abstract', 'class', 'connection', 'public', 'static', 'string', 'statetostring', 'int', 'state', 'switch', 'state', 'case', 'state', 'initializing', 'return', 'initializing', 'case', 'state', 'new', 'return', 'new', 'case', 'state', 'ringing']\n",
            "['similarity', 'index', '100', 'rename', 'from', 'examples', 'seneca', 'bug662', 'binary', 'html', 'rename', 'to', 'examples', 'seneca', 'bug662', 'test1', 'html']\n",
            "['modules', 'apps', 'collaboration', 'wiki', 'gitrepo', 'ppp', 'b', 'modules', 'apps', 'collaboration', 'wiki', 'gitrepo', 'subrepo', 'cmdver', 'liferay', 'commit', 'e17a5e5da4d8f1594040175129627f3e998a76cc', 'commit', 'ec7c0219d8d764010ba9493accae8be3c94785d7', 'mode', 'push', 'parent', 'f49454bc940a22bff107906ad639d2d6c5fff71e', 'parent', '3f2abcac9420152ba00be869ca3aa6cb47c07a24', 'remote', 'git', 'github', 'com', 'liferay', 'com', 'liferay', 'wiki', 'git', 'no', 'newline', 'at', 'end', 'of', 'file']\n",
            "['modules', 'apps', 'foundation', 'microsoft', 'translator', 'microsoft', 'translator', 'bnd', 'bnd', 'ppp', 'b', 'modules', 'apps', 'foundation', 'microsoft', 'translator', 'microsoft', 'translator', 'bnd', 'bnd', 'bundle', 'name', 'liferay', 'microsoft', 'translator', 'bundle', 'symbolicname', 'com', 'liferay', 'microsoft', 'translator', 'bundle', 'version', '1', '0', '0', 'no', 'newline', 'at', 'end', 'of', 'file', 'bundle', 'version', '1', '0', '1', 'no', 'newline', 'at', 'end', 'of', 'file']\n",
            "['new', 'file', 'mode', '100755', 'index', '0000000', 'd125c52', 'binary', 'files', 'dev', 'null', 'b', 'art', 'intro', 'png', 'differ']\n",
            "['telecomm', 'java', 'android', 'telecomm', 'connection', 'java', 'ppp', 'b', 'telecomm', 'java', 'android', 'telecomm', 'connection', 'java', 'public', 'abstract', 'class', 'connection', 'public', 'static', 'string', 'statetostring', 'int', 'state', 'switch', 'state', 'case', 'state', 'initializing', 'return', 'initializing', 'case', 'state', 'new', 'return', 'new', 'case', 'state', 'ringing']\n",
            "['similarity', 'index', '100', 'rename', 'examples', 'seneca', 'bug662', 'binary', 'html', 'rename', 'examples', 'seneca', 'bug662', 'test1', 'html']\n",
            "['modules', 'apps', 'collaboration', 'wiki', 'gitrepo', 'ppp', 'b', 'modules', 'apps', 'collaboration', 'wiki', 'gitrepo', 'subrepo', 'cmdver', 'liferay', 'commit', 'e17a5e5da4d8f1594040175129627f3e998a76cc', 'commit', 'ec7c0219d8d764010ba9493accae8be3c94785d7', 'mode', 'push', 'parent', 'f49454bc940a22bff107906ad639d2d6c5fff71e', 'parent', '3f2abcac9420152ba00be869ca3aa6cb47c07a24', 'remote', 'git', 'github', 'liferay', 'liferay', 'wiki', 'git', 'newline', 'file']\n",
            "['modules', 'apps', 'foundation', 'microsoft', 'translator', 'microsoft', 'translator', 'bnd', 'bnd', 'ppp', 'b', 'modules', 'apps', 'foundation', 'microsoft', 'translator', 'microsoft', 'translator', 'bnd', 'bnd', 'bundle', 'liferay', 'microsoft', 'translator', 'bundle', 'symbolicname', 'liferay', 'microsoft', 'translator', 'bundle', 'version', '1', '0', '0', 'newline', 'file', 'bundle', 'version', '1', '0', '1', 'newline', 'file']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlcEQ-oiYS2p",
        "colab_type": "text"
      },
      "source": [
        "Word Frequency in diffs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRCPO9sRjSjD",
        "colab_type": "text"
      },
      "source": [
        "Lots of \"words\" in the diffs are class name, function name or variable name in the code. We want to clean the data and remove the words with low frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbgamf_7R-tK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "53da11e3-d673-4392-bb49-e39ff18fe23c"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "#check the distribution of words, <50 low-frequency words and >=50 high-frequency words\n",
        "# total 61550; <50: 60266; >50: 1284\n",
        "word_dic = {}\n",
        "for diffs in diff_train_lemmatisation:\n",
        "  for i in diffs:\n",
        "    word_dic[i] = word_dic.get(i, 0) + 1\n",
        "for diffs in diff_test_lemmatisation:\n",
        "  for i in diffs:\n",
        "    word_dic[i] = word_dic.get(i, 0) + 1\n",
        "print (len(word_dic))\n",
        "\n",
        "# frequency = []\n",
        "# for i, num in word_dic.items():\n",
        "#   frequency.append(num)\n",
        "\n",
        "# plt.figure(0)\n",
        "# plt.xlabel('Word Frequency')\n",
        "# plt.ylabel('#Unique Words')\n",
        "# plt.title('Distribution')\n",
        "# plt.hist(frequency, bins = 10)\n",
        "\n",
        "# # <50 60266\n",
        "# low_frequency = []\n",
        "# for i in frequency:\n",
        "#   if i < 50:\n",
        "#     low_frequency.append(i)\n",
        "# print(len(low_frequency))\n",
        "\n",
        "# plt.figure(1)\n",
        "# plt.xlabel('Word Frequency')\n",
        "# plt.ylabel('#Unique Words')\n",
        "# plt.title('Low-Frequency-Word Distribution')\n",
        "# plt.hist(low_frequency, bins = 10)\n",
        "\n",
        "# # >=50 1284\n",
        "# high_frequency = []\n",
        "# for i in frequency:\n",
        "#   if i >= 50:\n",
        "#     high_frequency.append(i)\n",
        "# print(len(high_frequency))\n",
        "\n",
        "# plt.figure(2)\n",
        "# plt.xlabel('Word Frequency')\n",
        "# plt.ylabel('#Unique Words')\n",
        "# plt.title('High-Frequency-Word Distribution')\n",
        "# plt.hist(high_frequency, bins = 10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "61550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oNGsWIxhrLN",
        "colab_type": "text"
      },
      "source": [
        "Less-Frequency Words Removal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKooxrnPkUUz",
        "colab_type": "text"
      },
      "source": [
        "We will remove the words which appears less than 10 times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fdxvH_jhrl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "66522dea-9f89-4f54-a959-c85a16ab5048"
      },
      "source": [
        "filtered_diff_train = []\n",
        "for words in diff_train_lemmatisation:\n",
        "  frequent_words = []\n",
        "  for word in words:\n",
        "    if word_dic[word] >= 10:\n",
        "      frequent_words.append(word)\n",
        "  filtered_diff_train.append(frequent_words)\n",
        "\n",
        "filtered_diff_test = [] \n",
        "for words in diff_test_lemmatisation:\n",
        "  frequent_words = []\n",
        "  for word in words:\n",
        "    if word_dic[word] >= 10:\n",
        "      frequent_words.append(word)\n",
        "  filtered_diff_test.append(frequent_words)\n",
        "\n",
        "for i in range(0,10):\n",
        "  print(filtered_diff_train[i])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['new', 'file', 'mode', '100755', 'index', '0000000', 'binary', 'file', 'dev', 'null', 'b', 'art', 'intro', 'png', 'differ']\n",
            "['telecomm', 'java', 'android', 'telecomm', 'connection', 'java', 'ppp', 'b', 'telecomm', 'java', 'android', 'telecomm', 'connection', 'java', 'public', 'abstract', 'class', 'connection', 'public', 'static', 'string', 'int', 'state', 'switch', 'state', 'case', 'state', 'return', 'case', 'state', 'new', 'return', 'new', 'case', 'state']\n",
            "['similarity', 'index', '100', 'rename', 'example', 'binary', 'html', 'rename', 'example', 'html']\n",
            "['module', 'apps', 'collaboration', 'wiki', 'gitrepo', 'ppp', 'b', 'module', 'apps', 'collaboration', 'wiki', 'gitrepo', 'subrepo', 'cmdver', 'liferay', 'commit', 'commit', 'mode', 'push', 'parent', 'parent', 'remote', 'git', 'github', 'liferay', 'liferay', 'wiki', 'git', 'newline', 'file']\n",
            "['module', 'apps', 'foundation', 'microsoft', 'translator', 'microsoft', 'translator', 'bnd', 'bnd', 'ppp', 'b', 'module', 'apps', 'foundation', 'microsoft', 'translator', 'microsoft', 'translator', 'bnd', 'bnd', 'bundle', 'liferay', 'microsoft', 'translator', 'bundle', 'symbolicname', 'liferay', 'microsoft', 'translator', 'bundle', 'version', '1', '0', '0', 'newline', 'file', 'bundle', 'version', '1', '0', '1', 'newline', 'file']\n",
            "['module', 'apps', 'foundation', 'portal', 'cache', 'gitrepo', 'ppp', 'b', 'module', 'apps', 'foundation', 'portal', 'cache', 'gitrepo', 'subrepo', 'cmdver', 'liferay', 'commit', 'commit', 'mode', 'push', 'parent', 'parent', 'remote', 'git', 'github', 'liferay', 'liferay', 'portal', 'cache', 'git', 'newline', 'file']\n",
            "['lib', 'nokogiri', 'version', 'rb', 'ppp', 'b', 'lib', 'nokogiri', 'version', 'rb', 'module', 'nokogiri', 'version', '1', '0', '5', 'version', '1', '0', '6']\n",
            "['twidere', 'build', 'gradle', 'ppp', 'b', 'twidere', 'build', 'gradle', 'android', 'applicationid', 'org', 'mariotaku', 'twidere', 'minsdkversion', '14', 'targetsdkversion', '25', 'versioncode', 'versionname', '3', '3', '15', 'versioncode', 'versionname', '3', '3', '16', 'multidexenabled', 'true', 'buildconfigfield', 'boolean', 'leak_canary_enabled', 'boolean', 'parseboolean', 'true']\n",
            "['changelog', 'md', 'ppp', 'b', 'changelog', 'md', 'storm', 'make', 'bolt', 'method', 'cleaner', 'simpler', '1', '0', '0', 'storm', 'fix', 'wrong', 'package', 'storm', 'trident', 'storm', 'added', 'file', 'log4j', 'config', 'file', 'window', 'env', 'storm', 'drpc', 'issue', 'storm', 'fix', 'storm', 'documentation']\n",
            "['binary', 'file', 'png', 'b', 'png', 'differ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNleTzTrDCYi",
        "colab_type": "text"
      },
      "source": [
        "#Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7SjL98gISVm",
        "colab_type": "text"
      },
      "source": [
        "Add Paddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1orr-x-DClb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "cec6e82d-3415-4a02-8a61-3917b7e0b73f"
      },
      "source": [
        "#diff_len = [len(line) for line in filtered_diff_train]\n",
        "max_diff_length = max(len(line) for line in filtered_diff_train)\n",
        "max_msg_length = max(len(line) for line in msg_train_lemmatisation)\n",
        "print(max_diff_length, max_msg_length)\n",
        "def add_paddings(corpus, seq_length):\n",
        "    padding_list = []\n",
        "    for line in corpus:\n",
        "        if len(line) > seq_length:\n",
        "            padding_list.append(line[:seq_length])\n",
        "        else:\n",
        "            for j in range(seq_length - len(line)):\n",
        "                line.append(\"<PAD>\")\n",
        "            padding_list.append(line)\n",
        "    return padding_list\n",
        "\n",
        "padding_diff_train = add_paddings(filtered_diff_train, max_diff_length)\n",
        "padding_diff_test = add_paddings(filtered_diff_test, max_diff_length)\n",
        "\n",
        "padding_msg_train = add_paddings(msg_train_lemmatisation, max_msg_length)\n",
        "padding_msg_test = add_paddings(msg_train_lemmatisation, max_msg_length)\n",
        "for i in range(0,2):\n",
        "  print(padding_diff_train[i])\n",
        "\n",
        "for i in range(0,2):\n",
        "  print(padding_msg_train[i])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77 20\n",
            "['new', 'file', 'mode', '100755', 'index', '0000000', 'binary', 'file', 'dev', 'null', 'b', 'art', 'intro', 'png', 'differ', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['telecomm', 'java', 'android', 'telecomm', 'connection', 'java', 'ppp', 'b', 'telecomm', 'java', 'android', 'telecomm', 'connection', 'java', 'public', 'abstract', 'class', 'connection', 'public', 'static', 'string', 'int', 'state', 'switch', 'state', 'case', 'state', 'return', 'case', 'state', 'new', 'return', 'new', 'case', 'state', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['added', 'intro', 'image', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['fix', 'wtf', 'creating', 'lazily', 'initialized', 'connection', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05IqvlEqAbyS",
        "colab_type": "text"
      },
      "source": [
        "Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh2p5FzOAcKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "b985dd6f-93f7-41f3-856d-5f20190deb12"
      },
      "source": [
        "import gensim.downloader as api\n",
        "word_emb_model = api.load(\"glove-twitter-100\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA9Qh9lhE7wy",
        "colab_type": "text"
      },
      "source": [
        "Get Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ljJ_ATnE8G0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "outputId": "d6762130-eda6-40ea-89ee-541d98e7ce1d"
      },
      "source": [
        "import numpy as np\n",
        "def get_embeddings(corpus, word_emb_model):\n",
        "    emb_dim = word_emb_model.vector_size\n",
        "    out = []\n",
        "    for sentence in corpus:\n",
        "        out_temp = []\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                out_temp.append(word_emb_model.wv[word])\n",
        "            except:\n",
        "                out_temp.append([0]*emb_dim)\n",
        "    \n",
        "        out.append(out_temp)\n",
        "    return np.array(out)\n",
        "\n",
        "diff_train_embedding = get_embeddings(padding_diff_train, word_emb_model)\n",
        "diff_test_embedding = get_embeddings(padding_diff_test, word_emb_model)\n",
        "msg_train_embedding = get_embeddings(padding_msg_train, word_emb_model)\n",
        "msg_test_embedding = get_embeddings(padding_msg_test, word_emb_model)\n",
        "\n",
        "for i in range(0,2):\n",
        "  print(diff_train_embedding[i])\n",
        "\n",
        "for i in range(0,2):\n",
        "  print(msg_train_embedding[i])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[ 0.44806999 -0.018342   -0.31766    ... -0.12541001  0.11663\n",
            "  -0.05747   ]\n",
            " [ 0.33761001  0.35543001 -0.19471    ...  0.30792001 -0.41751999\n",
            "  -0.10321   ]\n",
            " [ 0.10837    -0.72222    -1.34609997 ...  0.19367    -0.21998\n",
            "  -0.61063999]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n",
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.13333     0.0085233  -0.54045999 ...  0.027566   -0.23100001\n",
            "  -0.19101   ]\n",
            " [-0.19347    -0.52441001 -1.05809999 ...  0.46393001  0.48500001\n",
            "  -0.82420999]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n",
            "[[ 0.40066001  0.20416    -0.45138001 ... -0.29279     0.29605001\n",
            "  -0.024056  ]\n",
            " [-0.17244001  0.74804002 -0.25413001 ...  0.37739     0.44545999\n",
            "   0.12417   ]\n",
            " [ 0.75544    -0.19163001 -0.73613    ... -0.71973002 -0.16204999\n",
            "  -0.13957   ]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n",
            "[[ 0.34928     0.3127      0.17794999 ...  0.46880001 -0.69160002\n",
            "  -0.31834999]\n",
            " [ 0.79023999  0.093292    0.20471001 ...  0.21517     0.74975997\n",
            "   0.44872999]\n",
            " [ 0.44606999 -0.00389     0.50480002 ... -0.037254   -0.15354\n",
            "  -0.82982999]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGu1A9vjHyzQ",
        "colab_type": "text"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLOfZmXXHzgz",
        "colab_type": "text"
      },
      "source": [
        "Hyperparameter Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ_uj29zHpbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_input = diff_train_embedding.shape[2]\n",
        "n_hidden = 50\n",
        "n_class = 26208\n",
        "total_epoch = 100\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfUgaAXbHpsO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "1a374861-b545-4db8-a8f6-00c30e087dc3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.lstm = nn.LSTM(n_input, n_hidden, num_layers=2, batch_first =True, dropout=0.2)\n",
        "        self.linear = nn.Linear(n_hidden, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x,_ = self.lstm(x)\n",
        "        x = self.linear(x[:,-1,:])\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net().to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "input_batch_torch = torch.from_numpy(np.array(diff_train_embedding)).float().to(device)\n",
        "target_batch_torch = torch.from_numpy(np.array(msg_train_embedding)).float().to(device)\n",
        "\n",
        "\n",
        "for epoch in range(total_epoch):   \n",
        "    net.train()\n",
        "    outputs = net(input_batch_torch) \n",
        "    loss = criterion(outputs, target_batch_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    net.eval()\n",
        "    outputs = net(input_batch_torch) \n",
        "    \n",
        "    if epoch%10 == 9:\n",
        "        loss = criterion(outputs, target_batch_torch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        acc= accuracy_score(predicted.cpu().numpy(),target_batch_torch.cpu().numpy())\n",
        "\n",
        "        print('Epoch: %d, loss: %.5f, train_acc: %.2f' %(epoch + 1, loss.item(), acc))\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-24502f9300e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch_torch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch_torch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-24502f9300e3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 559\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 386.00 MiB (GPU 0; 15.90 GiB total capacity; 14.05 GiB already allocated; 263.75 MiB free; 14.94 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    }
  ]
}